{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\n'''\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''    \nprint(os.listdir(\"../input/10-monkey-species\"))\nprint(os.listdir(\"../input/10-monkey-species/training\"))\nprint(os.listdir(\"../input/10-monkey-species/training/training\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport os\nimport sys\nimport time\nimport tensorflow as tf\nfrom tensorflow import keras\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n错误：\ntrain_dir = \"../input/10-monkey-species/training\"\nvalid_dir = \"../input/10-monkey-species/validation\"\nlabel_file = \"../input/10-monkey-species/monkey_labels.txt\"\n'''\ntrain_dir = \"../input/10-monkey-species/training/training\"\nvalid_dir = \"../input/10-monkey-species/validation/validation\"\nlabel_file = \"../input/10-monkey-species/monkey_labels.txt\"\nprint(os.path.exists(train_dir))\nprint(os.path.exists(valid_dir))\nprint(os.path.exists(label_file))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labels作用：子文件夹名字 --> 真正类别  的映射\n# 要是做inference， 需要转为真正的名字\nlabels = pd.read_csv(label_file, header=0)\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"height = 128\nwidth = 128\nchannels = 3\nbatch_size = 64\nnum_classes = 10\n\n# 读取数据，再增强\ntrain_datagen = keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1./255, \n    rotation_range = 40,       # 生成的角度在-40~40之间，不一定为40\n    width_shift_range = 0.2,   # 0-1之间的数为比例，>1为像素值\n    height_shift_range = 0.2,  # 与rotation_range一样，随机指定0~20%的位移\n    shear_range = 0.2,         # 剪切强度\n    zoom_range = 0.2,          # 缩放强度\n    horizontal_flip=True,      # 是否随机水平翻转\n    fill_mode = 'nearest'      # 填充像素的规则\n)\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                   target_size = (height, width),\n                                                   batch_size = batch_size,\n                                                   seed = 7, \n                                                   shuffle = True,\n                                                   class_mode = 'categorical')\nvalid_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\nvalid_generator = valid_datagen.flow_from_directory(valid_dir,\n                                                   target_size = (height, width),\n                                                   batch_size = batch_size,\n                                                   seed = 7, \n                                                   shuffle = False,\n                                                   class_mode = 'categorical')\ntrain_num = train_generator.samples\nvalid_num = valid_generator.samples\nprint(train_num, valid_num)\n\nfor i in range(2):\n    x, y = train_generator.next()\n    print(x.shape, y.shape)\n    print(y)\n'''\n异常处理：\ny.shape = （64， 1）\n经过one-hot编码之后应该是(64, 10)\n可能原因是路径中training, validation只有一个文件夹，就将所有的图片都划分成了一个类\n解决：在进一步打开文件夹\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.models.Sequential([\n    keras.layers.Conv2D(filters = 32,\n                        kernel_size = 3,\n                        padding = 'same',\n                        activation = 'relu',\n                        input_shape = (width, height, channels)),\n    keras.layers.Conv2D(filters = 32, \n                        kernel_size = 3,\n                        padding = 'same',\n                        activation = 'relu'),\n    keras.layers.MaxPool2D(pool_size = 2),\n    \n    keras.layers.Conv2D(filters = 64,\n                        kernel_size = 3,\n                        padding = 'same',\n                        activation = 'relu'),\n    keras.layers.Conv2D(filters = 64, \n                        kernel_size = 3,\n                        padding = 'same',\n                        activation = 'relu'),\n    keras.layers.MaxPool2D(pool_size = 2),\n    \n    keras.layers.Conv2D(filters = 128,\n                        kernel_size = 3,\n                        padding = 'same',\n                        activation = 'relu'),\n    keras.layers.Conv2D(filters = 128, \n                        kernel_size = 3,\n                        padding = 'same',\n                        activation = 'relu'),\n    keras.layers.MaxPool2D(pool_size = 2),\n    \n    keras.layers.Flatten(),\n    keras.layers.Dense(128, activation = 'relu'),\n    keras.layers.Dense(num_classes, activation = 'softmax')\n])\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam',\n              metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\nhistory = model.fit_generator(train_generator, \n                              steps_per_epoch = train_num // batch_size,\n                              epochs = epochs,\n                              validation_data = valid_generator,\n                              validation_steps = valid_num // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(history.history.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curve(history, label, epochs, min_value, max_value):\n    data = {}\n    data[label] = history.history[label]\n    data['val_' + label] = history.history['val_' + label]\n    pd.DataFrame(data).plot(figsize = (8, 5))\n    plt.grid()\n    plt.axis([0, epochs, min_value, max_value])\n    plt.show()\n    \nplot_learning_curve(history, 'loss', epochs, 1.3, 2.5)\nplot_learning_curve(history, 'accuracy', epochs, 0, 1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}