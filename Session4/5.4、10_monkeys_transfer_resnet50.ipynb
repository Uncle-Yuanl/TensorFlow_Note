{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "'''\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "'''    \n",
    "print(os.listdir(\"../input/10-monkey-species\"))\n",
    "print(os.listdir(\"../input/10-monkey-species/training\"))\n",
    "print(os.listdir(\"../input/10-monkey-species/training/training\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "错误：\n",
    "train_dir = \"../input/10-monkey-species/training\"\n",
    "valid_dir = \"../input/10-monkey-species/validation\"\n",
    "label_file = \"../input/10-monkey-species/monkey_labels.txt\"\n",
    "'''\n",
    "train_dir = \"../input/10-monkey-species/training/training\"\n",
    "valid_dir = \"../input/10-monkey-species/validation/validation\"\n",
    "label_file = \"../input/10-monkey-species/monkey_labels.txt\"\n",
    "print(os.path.exists(train_dir))\n",
    "print(os.path.exists(valid_dir))\n",
    "print(os.path.exists(label_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels作用：子文件夹名字 --> 真正类别  的映射\n",
    "# 要是做inference， 需要转为真正的名字\n",
    "labels = pd.read_csv(label_file, header=0)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "channels = 3\n",
    "batch_size = 24\n",
    "num_classes = 10\n",
    "\n",
    "# 读取数据，再增强\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    # 专门给resnet50定义的处理图像的函数， 作用为归一化 [-1, 1]\n",
    "    preprocessing_function = keras.applications.resnet50.preprocess_input, \n",
    "    # rescale = 1./255,\n",
    "    rotation_range = 40,       # 生成的角度在-40~40之间，不一定为40\n",
    "    width_shift_range = 0.2,   # 0-1之间的数为比例，>1为像素值\n",
    "    height_shift_range = 0.2,  # 与rotation_range一样，随机指定0~20%的位移\n",
    "    shear_range = 0.2,         # 剪切强度\n",
    "    zoom_range = 0.2,          # 缩放强度\n",
    "    horizontal_flip=True,      # 是否随机水平翻转\n",
    "    fill_mode = 'nearest'      # 填充像素的规则\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size = (height, width),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   seed = 7, \n",
    "                                                   shuffle = True,\n",
    "                                                   class_mode = 'categorical')\n",
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = keras.applications.resnet50.preprocess_input)\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir,\n",
    "                                                   target_size = (height, width),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   seed = 7, \n",
    "                                                   shuffle = False,\n",
    "                                                   class_mode = 'categorical')\n",
    "train_num = train_generator.samples\n",
    "valid_num = valid_generator.samples\n",
    "print(train_num, valid_num)\n",
    "\n",
    "for i in range(2):\n",
    "    x, y = train_generator.next()\n",
    "    print(x.shape, y.shape)\n",
    "    print(y)\n",
    "'''\n",
    "异常处理：\n",
    "y.shape = （64， 1）\n",
    "经过one-hot编码之后应该是(64, 10)\n",
    "可能原因是路径中training, validation只有一个文件夹，就将所有的图片都划分成了一个类\n",
    "解决：在进一步打开文件夹\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_fine_tune = keras.models.Sequential()\n",
    "resnet50_fine_tune.add(keras.applications.ResNet50(include_top = False, \n",
    "# ResNet50针对ImageNet训练，有1000类， 我们的问题只有10类，所以需要把最后一层给去掉，使能起迁移的作用\n",
    "                                                   pooling = 'avg',\n",
    "# ResNet50倒数第二层是一个卷积层的输出(三维的矩阵，而不是向量)，想要连接FC，1）pooling 2）展平                                         \n",
    "                                                   weights = 'imagenet'))\n",
    "# None:从头开始训练；imagenet:去下载一个已经在ImageNet上训练好的模型中的参数\n",
    "\n",
    "\n",
    "# 刚才去掉了最后一层，现在需要加上自己任务的全连接层\n",
    "resnet50_fine_tune.add(keras.layers.Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "# 设定trainable，固定下载的模型\n",
    "# resnet50_fine_tune将已有的50层作为一层，所以只要设置一次\n",
    "resnet50_fine_tune.layers[0].trainable = False\n",
    "\n",
    "resnet50_fine_tune.compile(loss = 'categorical_crossentropy', optimizer = 'sgd',  # fine_tune适合设置为'sgd'\n",
    "                           metrics = ['accuracy'])\n",
    "resnet50_fine_tune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = resnet50_fine_tune.fit_generator(train_generator, \n",
    "                                           steps_per_epoch = train_num // batch_size,\n",
    "                                           epochs = epochs,\n",
    "                                           validation_data = valid_generator,\n",
    "                                           validation_steps = valid_num // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(history, label, epochs, min_value, max_value):\n",
    "    data = {}\n",
    "    data[label] = history.history[label]\n",
    "    data['val_' + label] = history.history['val_' + label]\n",
    "    pd.DataFrame(data).plot(figsize = (8, 5))\n",
    "    plt.grid()\n",
    "    plt.axis([0, epochs, min_value, max_value])\n",
    "    plt.show()\n",
    "    \n",
    "plot_learning_curve(history, 'loss', epochs, 0, 2)\n",
    "plot_learning_curve(history, 'accuracy', epochs, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fine_tune ResNet50层中的最后几层\n",
    "resnet50 = keras.applications.ResNet50(include_top = False, \n",
    "                                                   pooling = 'avg',                                        \n",
    "                                                   weights = 'imagenet')\n",
    "resnet50.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对后除了五层以外所有层次遍历\n",
    "for layer in resnet50.layers[0: -5]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# 组合\n",
    "resnet50_new = keras.models.Sequential([\n",
    "    resnet50,\n",
    "    keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "])\n",
    "\n",
    "resnet50_new.compile(loss = 'categorical_crossentropy', optimizer = 'sgd',  # fine_tune适合设置为'sgd'\n",
    "                           metrics = ['accuracy'])\n",
    "resnet50_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = resnet50_new.fit_generator(train_generator, \n",
    "                                     steps_per_epoch = train_num // batch_size,\n",
    "                                     epochs = epochs,\n",
    "                                     validation_data = valid_generator,\n",
    "                                     validation_steps = valid_num // batch_size)\n",
    "# 结果可能变差：\n",
    "# 1）可训练参数变多，需要更多的epoch来达到更好的效果\n",
    "# 2）trainbale层中游一部分为ResNet原来的层，以及新加的全连接层。\n",
    "# 原来的层i)通过前面很多层训练非常出色的权重没有了  ii)需要配合新的层的学习率，导致原本的能力没有发挥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
