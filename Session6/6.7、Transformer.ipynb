{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1、 load datas\n",
    "2、 preprocess\n",
    "3、 tools\n",
    "3.1、 generate position embedding\n",
    "3.2、 creat mask (a. padding. b. decoder)\n",
    "3.3、 scaled_dot_producte_attention\n",
    "4、 build model\n",
    "4.1、 Multi-Head Attention\n",
    "4.2、 EncoderLayer\n",
    "4.3、 DecoderLayer\n",
    "4.4、 EncoderModel\n",
    "4.5、 DecoderModel\n",
    "4.6、 Transformer\n",
    "5、 loss & optimizer\n",
    "6、 train step\n",
    "7、 Evaluate and Visualize\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='ted_hrlr_translate',\n",
      "    version=1.0.0,\n",
      "    description='Data sets derived from TED talk transcripts for comparing similar language pairs\n",
      "where one is high resource and the other is low resource.\n",
      "',\n",
      "    homepage='https://github.com/neulab/word-embeddings-for-nmt',\n",
      "    features=Translation({\n",
      "        'en': Text(shape=(), dtype=tf.string),\n",
      "        'pt': Text(shape=(), dtype=tf.string),\n",
      "    }),\n",
      "    total_num_examples=54781,\n",
      "    splits={\n",
      "        'test': 1803,\n",
      "        'train': 51785,\n",
      "        'validation': 1193,\n",
      "    },\n",
      "    supervised_keys=('pt', 'en'),\n",
      "    citation=\"\"\"@inproceedings{Ye2018WordEmbeddings,\n",
      "      author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n",
      "      title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n",
      "      booktitle = {HLT-NAACL},\n",
      "      year    = {2018},\n",
      "      }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "examples, info = tfds.load('ted_hrlr_translate/pt_to_en', \n",
    "                           with_info = True, \n",
    "                           as_supervised = True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'e quando melhoramos a procura , tiramos a \\xc3\\xbanica vantagem da impress\\xc3\\xa3o , que \\xc3\\xa9 a serendipidade .'\n",
      "b'and when you improve searchability , you actually take away the one advantage of print , which is serendipity .'\n",
      "\n",
      "b'mas e se estes fatores fossem ativos ?'\n",
      "b'but what if it were active ?'\n",
      "\n",
      "b'mas eles n\\xc3\\xa3o tinham a curiosidade de me testar .'\n",
      "b\"but they did n't test for curiosity .\"\n",
      "\n",
      "b'e esta rebeldia consciente \\xc3\\xa9 a raz\\xc3\\xa3o pela qual eu , como agn\\xc3\\xb3stica , posso ainda ter f\\xc3\\xa9 .'\n",
      "b'and this conscious defiance is why i , as an agnostic , can still have faith .'\n",
      "\n",
      "b\"`` `` '' podem usar tudo sobre a mesa no meu corpo . ''\"\n",
      "b'you can use everything on the table on me .'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 导入的数据已经是dataset，里面都是tensor\n",
    "# .numpy() 后才是单词组成的句子\n",
    "for pt, en in train_examples.take(5):\n",
    "    print(pt.numpy())\n",
    "    print(en.numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转为sub_word数据集\n",
    "# 从语料中构建sub_word词表的方法：build_from_corpus\n",
    "en_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), \n",
    "    target_vocab_size = 2 ** 13)\n",
    "pt_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples),\n",
    "    target_vocab_size = 2 ** 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799]\n",
      "The original string is Transformer is awesome\n",
      "7915 --> \"T\"\n",
      "1248 --> \"ran\"\n",
      "7946 --> \"s\"\n",
      "7194 --> \"former \"\n",
      "13 --> \"is \"\n",
      "2799 --> \"awesome\"\n"
     ]
    }
   ],
   "source": [
    "# 试用tokenizer\n",
    "sample_string = 'Transformer is awesome'\n",
    "\n",
    "# 单词 --> id\n",
    "tokenized_string = en_tokenizer.encode(sample_string)\n",
    "print(\"Tokenized string is {}\".format(tokenized_string))\n",
    "\n",
    "# id --> 单词\n",
    "origin_string = en_tokenizer.decode(tokenized_string)\n",
    "print(\"The original string is {}\".format(origin_string))\n",
    "\n",
    "assert origin_string == sample_string\n",
    "\n",
    "for token in tokenized_string:\n",
    "    # decode 传入的需要是list\n",
    "    # \"{}\"可以让我们看出空格在哪里\n",
    "    print('{} --> \"{}\"'.format(token, en_tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8214\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received id 8214 which is invalid. Ids must be within [0, 8214).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fa341e8b884d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8214\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.6/site-packages/tensorflow_datasets/core/features/text/subword_text_encoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubword_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubword_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m       \u001b[0msubword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id_to_subword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubword_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Byte-encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.6/site-packages/tensorflow_datasets/core/features/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_id_to_subword\u001b[0;34m(self, subword_id)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubword_id\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msubword_id\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       raise ValueError(\"Received id %d which is invalid. Ids must be within \"\n\u001b[0;32m--> 178\u001b[0;31m                        \"[0, %d).\" % (subword_id + 1, self.vocab_size))\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0msubword_id\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Received id 8214 which is invalid. Ids must be within [0, 8214)."
     ]
    }
   ],
   "source": [
    "print(pt_tokenizer.vocab_size)\n",
    "print(pt_tokenizer.decode([8214]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据集\n",
    "buffer_size = 20000\n",
    "batch_size = 64\n",
    "max_length = 40\n",
    "\n",
    "def encode_to_subword(pt_sentence, en_sentence):\n",
    "    # 需要给句子前后各加一个特殊字符\n",
    "    # 开头 <start>id  结尾 <end>id\n",
    "    # tokenizer里 id是  0 -> vocab_size -1\n",
    "    # \\ 后面不能加空格\n",
    "    pt_sequence = [pt_tokenizer.vocab_size] \\\n",
    "    + pt_tokenizer.encode(pt_sentence.numpy()) \\\n",
    "    + [pt_tokenizer.vocab_size + 1]\n",
    "    \n",
    "    en_sequence = [en_tokenizer.vocab_size] \\\n",
    "    + en_tokenizer.encode(en_sentence.numpy()) \\\n",
    "    + [en_tokenizer.vocab_size + 1]\n",
    "    return pt_sequence, en_sequence\n",
    "\n",
    "# 将低于max_length的数据样本过滤\n",
    "# 返回布尔值\n",
    "def filter_by_max_length(pt, en):\n",
    "    # 处理的可能是tensor，所以用tf的API\n",
    "    return tf.logical_and(tf.size(pt) <= max_length,\n",
    "                          tf.size(en) <= max_length)\n",
    "\n",
    "# 封装python函数\n",
    "# 因为我们在调用dataset的map函数时不能够直接调用python函数\n",
    "def tf_encode_to_subword(pt_sentence, en_sentence):\n",
    "    return tf.py_function(encode_to_subword,\n",
    "                          [pt_sentence, en_sentence],\n",
    "                          [tf.int64, tf.int64])\n",
    "\n",
    "# 处理dataset\n",
    "# map：train_examples里面的所有葡萄牙语和英语的句子转为subword的id\n",
    "train_dataset = train_examples.map(tf_encode_to_subword)\n",
    "train_dataset = train_dataset.filter(filter_by_max_length)\n",
    "# ([-1], [-1]) 有两个维度，每个维度都扩展到最高的值\n",
    "train_dataset = train_dataset.shuffle(\n",
    "    buffer_size).padded_batch(\n",
    "    batch_size, padded_shapes = ([-1], [-1]))\n",
    "\n",
    "valid_dataset = val_examples.map(tf_encode_to_subword)\n",
    "valid_dataset = valid_dataset.filter(filter_by_max_length)\n",
    "valid_dataset = valid_dataset.padded_batch(batch_size, padded_shapes = ([-1], [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 38) (64, 40)\n",
      "(64, 39) (64, 35)\n",
      "(64, 39) (64, 39)\n",
      "(64, 39) (64, 39)\n",
      "(64, 39) (64, 36)\n"
     ]
    }
   ],
   "source": [
    "for pt_batch, en_batch in valid_dataset.take(5):\n",
    "    print(pt_batch.shape, en_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "# 3、tools\n",
    "# 位置编码\n",
    "# PE(pose, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "# PE(pose, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "    # pos: 词语在句子中的位置  shape = [sentence_length, 1]\n",
    "    # i: 词语在embedding中的位置  shape = [1, d_model]\n",
    "    # d_model: embedding的大小\n",
    "    # result.shape = [sentence_legth, d_model]\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def get_position_embedding(sentence_length, d_model):\n",
    "    angle_rads = get_angles(np.arange(sentence_length)[:, np.newaxis],\n",
    "                             np.arange(d_model)[np.newaxis, :],\n",
    "                             d_model)\n",
    "    # 取偶数位置 shape = [sentence_legth, d_model/2]\n",
    "    sines = np.sin(angle_rads[:, 0::2])\n",
    "    # 取奇数位  shape = [sentence_length, d_model/2]\n",
    "    cosines = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    # shape = [sentence_length, d_model]\n",
    "    position_embedding = np.concatenate([sines, cosines], axis = -1)\n",
    "    # shape = [1, sentence_length, d_model]\n",
    "    position_embedding = position_embedding[np.newaxis, ...]\n",
    "    return tf.cast(position_embedding, dtype = tf.float32)\n",
    "\n",
    "position_embedding = get_position_embedding(50, 512)\n",
    "print(position_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_position_embedding(position_embedding):\n",
    "    plt.pcolormesh(position_embedding[0], cmap = 'RdBu')\n",
    "    plt.xlabel(\"Depth\")\n",
    "    plt.ylabel(\"Position\")\n",
    "    plt.xlim(0, 512)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "plot_position_embedding(position_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成mask\n",
    "# 1、padding mask  self-attention也需要将padding mask掉\n",
    "\n",
    "# batch_data.shape = [batch_size, seq_len]\n",
    "def creat_padding_mask(batch_data):\n",
    "    padding_mask = tf.cast(tf.math.equal(batch_data, 0), tf.float32)\n",
    "    # shape = [batch_size, 1, 1, seq_len]\n",
    "    # 为了与attention_weights更加方便计算\n",
    "    return padding_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "creat_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "attention_weights.shape = [3, 3]\n",
    "[[1, 2, 3],\n",
    " [4, 5, 6],\n",
    " [7, 8, 9]]\n",
    " aij: 第i个单词跟第j个单词的attention。若要达到第i个单词只与他之前的单词有关系，则：\n",
    "[[1, 0, 0],\n",
    " [4, 5, 0],\n",
    " [7, 8, 9]]\n",
    " 下三角矩阵，mask罩在矩阵主对角线之上\n",
    " 矩阵中被mask的标记成1，不被mask标记成0\n",
    "'''\n",
    "\n",
    "def creat_look_ahead_mask(size):\n",
    "    # lower_band = -1 --> 主对角线 下=1，上=0\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    # shape = (seq_len, seq_len)\n",
    "    return mask\n",
    "\n",
    "creat_look_ahead_mask(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention_weights:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n",
      "Attention_weights:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n",
      "Attention_weights:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n",
      "Attention_weights:\n",
      "tf.Tensor(\n",
      "[[0.  1.  0.  0. ]\n",
      " [0.  0.  0.5 0.5]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output:\n",
      "tf.Tensor(\n",
      "[[ 10.    0. ]\n",
      " [550.    5.5]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 缩放点积注意力\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    '''\n",
    "    q.shape = (..., seq_len_q, depth)\n",
    "    k.shape = (..., seq_len_q, depth)\n",
    "    v.shape = (..., seq_len_v, depth_v)\n",
    "    seq_len_k == seq_len_v\n",
    "    q * k^T 后mask，mask.shape = (..., seq_len_q, seq_len_k)\n",
    "    renturns:\n",
    "        output : weighted sum\n",
    "        attention_weights: \n",
    "    '''\n",
    "    # transpose_b:转置第二个矩阵\n",
    "    # 只对后两个维度做矩阵乘法\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b = True)\n",
    "    \n",
    "    dk = tf.cast(tf.shape(k)[-1], dtype = tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    if mask is not None:\n",
    "        # logits会经过softmax，使得其softmax之后的值无限接近于0，达到mask效果\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "        \n",
    "    # attention_weights.shape = (..., seq_len_q, seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)\n",
    "    \n",
    "    # shape = (..., seq_len_q, depth_v)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    \n",
    "    return output, attention_weights\n",
    "\n",
    "def print_scaled_dot_product_attention(q, k, v):\n",
    "    temp_out, temp_att = scaled_dot_product_attention(q, k, v, None)\n",
    "    print(\"Attention_weights:\")\n",
    "    print(temp_att)\n",
    "    print(\"Output:\")\n",
    "    print(temp_out)\n",
    "    \n",
    "temp_k = tf.constant([[10, 0, 0], \n",
    "                      [0, 10, 0], \n",
    "                      [0, 0, 10], \n",
    "                      [0, 0, 10]], dtype = tf.float32) # (4, 3)\n",
    "temp_v = tf.constant([[1, 0], \n",
    "                      [10, 0], \n",
    "                      [100, 5], \n",
    "                      [1000, 6]], dtype = tf.float32)  # (4, 2)\n",
    "temp_q1 = tf.constant([[0, 10, 0]], dtype = tf.float32) # (1, 3)\n",
    "np.set_printoptions(suppress = True)\n",
    "print_scaled_dot_product_attention(temp_q1, temp_k, temp_v)\n",
    "\n",
    "temp_q2 = tf.constant([[0, 0, 10]], dtype = tf.float32) # (1, 3)\n",
    "print_scaled_dot_product_attention(temp_q2, temp_k, temp_v)\n",
    "\n",
    "temp_q3 = tf.constant([[10, 10, 0]], dtype = tf.float32)\n",
    "print_scaled_dot_product_attention(temp_q3, temp_k, temp_v)\n",
    "\n",
    "temp_q4 = tf.constant([[0, 10, 0],\n",
    "                       [0, 0, 10],\n",
    "                       [10, 10, 0]], dtype = tf.float32)\n",
    "print_scaled_dot_product_attention(temp_q4, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60, 512)\n",
      "(1, 8, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "# Multi-Head Attention\n",
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    '''\n",
    "    理论中：同一个x\n",
    "    x -> wq0 -> q0\n",
    "    x -> wk0 -> k0\n",
    "    x -> wv0 -> v0\n",
    "    实践中：初始的值不一定是一样的\n",
    "           slef-attention中q，k，v是一样的\n",
    "           encoder和decoder的attention来说k和v是一样的，q不一样\n",
    "    q -> wq0 -> q0 \n",
    "      -> wq1 -> q1   实现技巧：\n",
    "      ...                   q -> wq -> Q -> split -> q0, q1, q2,...\n",
    "    k -> wk0 -> k0\n",
    "      ...\n",
    "    v -> wv0 -> v0\n",
    "      ...\n",
    "    得到的结果q0，q1，..，k0，...,v0,...再做多头注意力\n",
    "    '''\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert self.d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = self.d_model // self.num_heads\n",
    "        \n",
    "        self.WQ = keras.layers.Dense(self.d_model)\n",
    "        self.WK = keras.layers.Dense(self.d_model)\n",
    "        self.WV = keras.layers.Dense(self.d_model)\n",
    "        \n",
    "        self.dense = keras.layers.Dense(self.d_model)\n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        # x.shape = (batch_size, seq_len, d_model)\n",
    "        # d_model = num_heads * depth\n",
    "        # x -> (batch_size, num_heads, seq_len, depth)\n",
    "        \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        # 重排列\n",
    "        # 因为在saled_dot_product_attention函数中，是用后两个维度计算attention\n",
    "        # 所以需要将num_heads先换到前面去，再换回来\n",
    "        return tf.transpose(x, perm = [0, 2, 1, 3])\n",
    "               \n",
    "    def call(self, q, k, v, mask):\n",
    "        # 取出batch_size\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        # 让q,k,v分别经过全联接层\n",
    "        # embedding  -> shape = (batch_size, seq_len, embedding_dim)\n",
    "        # 中间层输出   -> shape = (batch_size, seq_dim, output_dim_last_step)\n",
    "        q = self.WQ(q) # q.shape = (batch_size, seq_len_q, d_model)\n",
    "        k = self.WK(k) # k.shape = (batch_size, seq_len_k, d_model)\n",
    "        v = self.WV(v) # v.shape = (batch_size, seq_len_v, d_model)\n",
    "        \n",
    "        # shape = (batch_size, num_heads, seq_len_q(k,v), depth)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        # scaled_attention_output.shape = (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape = (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention_outputs, attention_weights = \\\n",
    "        scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        # 拼接 多头的信息存在第二维和第四维中，需要先2、3维换位置， 再拼接3、4维\n",
    "        # shape = (batch_size, seq_len_q, num_heads, depth)\n",
    "        scaled_attention_outputs = tf.transpose(scaled_attention_outputs,\n",
    "                                                perm = [0, 2, 1, 3])\n",
    "        # shape = (batch_size, seq_len_q, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention_outputs, \n",
    "                                      (batch_size, -1, self.d_model))\n",
    "        \n",
    "        # shape = (batch_size, seq_len_q, d_model)\n",
    "        output = self.dense(concat_attention)\n",
    "        return output, attention_weights\n",
    "\n",
    "temp_mha = MultiHeadAttention(d_model = 512, num_heads = 8)\n",
    "y = tf.random.uniform((1, 60, 256)) # (batch_size, seq_len_q, dim)\n",
    "output, attn = temp_mha(y, y, y, mask = None)\n",
    "print(output.shape)\n",
    "print(attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feed_forward_network(d_model, dff):\n",
    "    # dff: dim of feed_forward network\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Dense(dff, activation = 'relu'),\n",
    "        keras.layers.Dense(d_model)\n",
    "    ])\n",
    "\n",
    "sample_fnn = feed_forward_network(512, 2048)\n",
    "sample_fnn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "# EncoderLayer\n",
    "class EncoderLayer(keras.layers.Layer):\n",
    "    '''\n",
    "    block: + dropout\n",
    "    x -> self_attention -> add & norm & dropout-> feed_forward -> add & norm & dropout\n",
    "    '''\n",
    "    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layer_norm1 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layer_norm2 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, encoder_padding_mask):\n",
    "        # x.shape = (batch_size, seq_len, dim)\n",
    "        # attn_output.shape = (batch_size, seq_len, d_model)\n",
    "        attn_output, _ = self.mha(x, x, x, encoder_padding_mask)\n",
    "        # dropout在训练和和测试的时候反应是不一样的\n",
    "        attn_output = self.dropout1(attn_output, training = training)\n",
    "        # \" + \" 要求 dim = d_model \n",
    "        out1 = self.layer_norm1(x + attn_output)\n",
    "        \n",
    "        # ffn_output.shape = (batch_size, seq_len, d_model)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training = training)\n",
    "        out2 = self.layer_norm2(out1 + ffn_output)\n",
    "        \n",
    "        # decoder只一个输出\n",
    "        return out2\n",
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "sample_input = tf.random.uniform((64, 50, 512))\n",
    "sample_output = sample_encoder_layer(sample_input, False, None)\n",
    "print(sample_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60, 512)\n",
      "(64, 8, 60, 60)\n",
      "(64, 8, 60, 50)\n"
     ]
    }
   ],
   "source": [
    "# 多一个Encoder和Decoder之间的MultiHeadAttention\n",
    "# 多一个层次\n",
    "\n",
    "class DecoderLayer(keras.layers.Layer):\n",
    "    '''\n",
    "    x -> self_attention -> add & norm & dropout -> out1\n",
    "    out1 + encoding_outputs -> attention -> add & norm & dropout -> out2\n",
    "    out2 -> ffn -> add & norm & dropout -> out3\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        # 初始化两个MultiHeadAttenion层\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layer_norm1 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layer_norm2 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layer_norm3 = keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        self.dropout3 = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, encoding_outputs, training, \n",
    "             decoder_mask, encoder_decoder_padding_mask):\n",
    "        # decoder_mask :look_ahead_mask logical_and deocder_padding_mask \n",
    "        # x.shape = (batch_size, target_seq_len, d_model_decoder)\n",
    "        # encoding_outputs.shape = (batch_size, input_seq_len, d_model_encoder)\n",
    "        # d_model_encoder = d_model_decoder\n",
    "        \n",
    "        # attn1, out1.shape = (batch_size, target_seq_len, d_model)\n",
    "        attn1, attn_weights1 = self.mha1(x, x, x, decoder_mask)\n",
    "        attn1 = self.dropout1(attn1, training = training)\n",
    "        out1 = self.layer_norm1(x + attn1)\n",
    "        \n",
    "        # attn2, out2.shape = (batch_size, target_seq_len, d_model)\n",
    "        attn2, attn_weights2 = self.mha2(out1, encoding_outputs, encoding_outputs, \n",
    "                                         encoder_decoder_padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training = training)\n",
    "        out2 = self.layer_norm2(out1 + attn2)\n",
    "        \n",
    "        # ffn_output, out3 = (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training = training)\n",
    "        out3 = self.layer_norm3(out2 + ffn_output)\n",
    "        \n",
    "        return out3, attn_weights1, attn_weights2\n",
    "    \n",
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "sample_decoder_input = tf.random.uniform((64, 60, 512))\n",
    "sample_decoder_output, sample_decoder_aw1, sample_decoder_aw2 = sample_decoder_layer(\n",
    "    sample_decoder_input, sample_output, False, None, None)\n",
    "print(sample_decoder_output.shape)\n",
    "print(sample_decoder_aw1.shape)\n",
    "print(sample_decoder_aw2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37, 512)\n"
     ]
    }
   ],
   "source": [
    "# 建立EncoderModel\n",
    "class EncoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, input_vocab_size, max_length,\n",
    "                 d_model, num_heads, dff, rate = 0.1):\n",
    "        super(EncoderModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "    \n",
    "        self.embedding = keras.layers.Embedding(input_vocab_size, self.d_model)\n",
    "    \n",
    "        # position_embedding.shape = (1, max_lengthm d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length, self.d_model)\n",
    "    \n",
    "    \n",
    "        # 在获得的embedding上做dropout\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        self.encoder_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                                for _ in range(self.num_layers)]\n",
    "    \n",
    "    def call(self, x, training, encoder_padding_mask):\n",
    "        # x.shape = (batch_size, input_seq_len)\n",
    "        input_seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        # 验证输入\n",
    "        # error\n",
    "        # assert input_seq_len <= self.max_length\n",
    "        tf.debugging.assert_less_equal(input_seq_len, self.max_length,\n",
    "                            \"input_seq_len should be less or equal to self.max_length\")\n",
    "        \n",
    "        # x.shape = (batch_size, input_seq_len, d_model)\n",
    "        x = self.embedding(x)\n",
    "        # 做这个缩放的原因是：\n",
    "        # x默认embedding初始化的时候是在【0，1】的均匀分布取到的\n",
    "        # 缩放后x属于【0，d_model】\n",
    "        # 是的缩放后的x加上position_embedding x本身起的作用会比较大一些\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        # x_len 可能 < max_len, 所以切片 而第一个维度会被复制 1 --> batch_size\n",
    "        x += self.position_embedding[:, input_seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training = training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.encoder_layers[i](x, training, encoder_padding_mask)\n",
    "            \n",
    "        # x.shape = (batch_size, input_seq_len, d_model)\n",
    "        return x    \n",
    "    \n",
    "sample_encoder_model = EncoderModel(2, 8500, max_length, 512, 8, 2048)\n",
    "sample_encoder_model_input = tf.random.uniform((64, 37))\n",
    "sample_encoder_model_output = sample_encoder_model(sample_encoder_model_input, \n",
    "                                                   False, encoder_padding_mask = None)\n",
    "print(sample_encoder_model_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 35, 512)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n"
     ]
    }
   ],
   "source": [
    "class DecoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, target_vocab_size, max_length, \n",
    "                 d_model, num_heads, dff, rate = 0.1):\n",
    "        super(DecoderModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length, d_model)\n",
    "        \n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        self.decoder_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                               for _ in range(self.num_layers)]\n",
    "    \n",
    "    def call(self, x, encoding_outputs, training, \n",
    "             decoder_mask, encoder_decoder_padding_mask):\n",
    "        # x.shape = (batch_size, output_seq_len)\n",
    "        output_seq_len = tf.shape(x)[1]\n",
    "        # assert output_seq_len <= self.max_length\n",
    "        # 报错：tensor不能用布尔值\n",
    "        tf.debugging.assert_less_equal(output_seq_len, self.max_length,\n",
    "                             \"output_seq_len should be less or equal self.max_length\")\n",
    "        \n",
    "        \n",
    "        attention_weights = {}\n",
    "        \n",
    "        # x.shape = (batch_size, output_seq_len, d_model)\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.position_embedding[:, output_seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training = training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x, attn1, attn2 = self.decoder_layers[i](x, encoding_outputs, training, \n",
    "                                                     decoder_mask, \n",
    "                                                     encoder_decoder_padding_mask)\n",
    "            attention_weights['decoder_layer{}_attn1'.format(i + 1)] = attn1\n",
    "            attention_weights['decoder_layer{}_attn2'.format(i + 1)] = attn2\n",
    "        # x.shape = (batch_size, output_seq_len, d_model)\n",
    "        return x, attention_weights\n",
    "\n",
    "sample_decoder_model = DecoderModel(2, 8000, max_length, 512, 8, 2048)\n",
    "sample_decoder_model_input = tf.random.uniform((64, 35))\n",
    "sample_decoder_model_output, sample_decoder_model_attn = sample_decoder_model(\n",
    "    sample_decoder_model_input, \n",
    "    sample_encoder_model_output, \n",
    "    training = False, decoder_mask = None, encoder_decoder_padding_mask = None)\n",
    "print(sample_decoder_model_output.shape)\n",
    "for key in sample_decoder_model_attn:\n",
    "    print(sample_decoder_model_attn[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 31, 8000)\n",
      "(64, 8, 31, 31)\n",
      "(64, 8, 31, 26)\n",
      "(64, 8, 31, 31)\n",
      "(64, 8, 31, 26)\n"
     ]
    }
   ],
   "source": [
    "# 形成Transformer\n",
    "# 最后一个大model继承keras.Model\n",
    "class Transformer(keras.Model):\n",
    "    def __init__(self, num_layers, input_vocab_size, target_vocab_size, max_length,\n",
    "                 d_model, num_heads, dff, rate = 0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_model = EncoderModel(num_layers, input_vocab_size, max_length,\n",
    "                                          d_model, num_heads, dff, rate)\n",
    "        self.decoder_model = DecoderModel(num_layers, target_vocab_size, max_length,\n",
    "                                          d_model, num_heads, dff, rate)\n",
    "        \n",
    "        # 接受docoder_layer的输出，再映射到词表大小的空间中去\n",
    "        self.final_layer = keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, encoder_padding_mask, \n",
    "             decoder_mask, encoder_decoder_padding_mask):\n",
    "        # shape = (batch_size, input_seq_len, d_model)\n",
    "        encoding_outputs = self.encoder_model(inp, training, encoder_padding_mask)\n",
    "        \n",
    "        # shape = (batch_size, output_seq_len, d_model)\n",
    "        decoding_outputs, attention_weights = self.decoder_model(tar, encoding_outputs,\n",
    "                                                                 training, \n",
    "                                                                 decoder_mask,\n",
    "                                                                 encoder_decoder_padding_mask)\n",
    "        # shape = (batch_size, outout_seq_len, traget_vocab_size)\n",
    "        predictions = self.final_layer(decoding_outputs)\n",
    "        \n",
    "        return predictions, attention_weights\n",
    "    \n",
    "sample_transformer = Transformer(2, 8500, 8000, max_length, 512, 8, 2048, rate = 0.1)\n",
    "temp_input = tf.random.uniform((64, 26))\n",
    "temp_target = tf.random.uniform((64, 31))\n",
    "\n",
    "predictions, attention_weights = sample_transformer(temp_input, temp_target,\n",
    "                                                    training = False,\n",
    "                                                    encoder_padding_mask = None,\n",
    "                                                    decoder_mask = None,\n",
    "                                                    encoder_decoder_padding_mask = None)\n",
    "print(predictions.shape)\n",
    "for key in attention_weights:\n",
    "    print(attention_weights[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "# 1、initializes model\n",
    "# 2、define loss optimizer, learning_rate schedule\n",
    "# 3、train_step 单步训练\n",
    "# 4、包装train_step  train_process \n",
    "\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = pt_tokenizer.vocab_size + 2\n",
    "target_vocab_size = en_tokenizer.vocab_size + 2\n",
    "\n",
    "dropout_rate = 0.1\n",
    "\n",
    "transformer = Transformer(num_layers,\n",
    "                          input_vocab_size,\n",
    "                          target_vocab_size,\n",
    "                          max_length,\n",
    "                          d_model, num_heads, dff, dropout_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# paper: lrate = (d_model ** (-0.5) * min(step_num ** (-0.5), \n",
    "#                                     step_num * warm_up_steps ** (-1.5))\n",
    "\n",
    "class CustomizedSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps = 4000):\n",
    "        super(CustomizedSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    # 注意这里的函数名！！\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** (-1.5))\n",
    "        \n",
    "        arg3 = tf.math.rsqrt(self.d_model)\n",
    "        \n",
    "        return arg3 * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "# 模型（d_model）越大，arg3越小，learning_rate越小\n",
    "learning_rate = CustomizedSchedule(d_model)\n",
    "optimizer = keras.optimizers.Adam(learning_rate, \n",
    "                                  beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Learning rate')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learning_rate 可视化\n",
    "temp_lrs = CustomizedSchedule(d_model)\n",
    "plt.plot(temp_lrs(tf.range(40000, dtype = tf.float32)))\n",
    "plt.xlabel(\"Train steps\")\n",
    "plt.ylabel(\"Learning rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits = True, \n",
    "                                                         reduction = 'none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype = loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 36) (64, 40)\n",
      "(64, 1, 1, 36)\n",
      "(64, 1, 1, 36)\n",
      "(40, 40)\n",
      "(64, 1, 1, 40)\n",
      "(64, 1, 40, 40)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 1, 1, 36), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1, 40, 40), dtype=float32, numpy=\n",
       " array([[[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1, 1, 36), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据需要创建mask\n",
    "def creat_masks(inp, tar):\n",
    "    '''\n",
    "    需要的masks：\n",
    "      - encoder_padding_mask (self_attention of EncoderLayer)\n",
    "      - decoder_look_ahead_mask (self_attenion of DecoderLayer)\n",
    "      - decoder_padding_mask  (self_attention of DecoderLayer) \n",
    "      # 一个attention两个mask 与操作\n",
    "      - encoder_decoder_padding_mask (encoder-decoder attention of DecoderLayer)\n",
    "    '''\n",
    "    \n",
    "    encoder_padding_mask = creat_padding_mask(inp)\n",
    "    encoder_decoder_padding_mask = creat_padding_mask(inp)\n",
    "    \n",
    "    look_ahead_mask = creat_look_ahead_mask(tf.shape(tar)[1])\n",
    "    decoder_padding_mask = creat_padding_mask(tar)\n",
    "    # 合并 被mask的为1，不被mask的为0\n",
    "    # 与操作与取最大值操作等价\n",
    "    decoder_mask = tf.maximum(decoder_padding_mask, look_ahead_mask)\n",
    "    \n",
    "    print(encoder_padding_mask.shape)\n",
    "    print(encoder_decoder_padding_mask.shape)\n",
    "    print(look_ahead_mask.shape)      # (39, 39)       --> (64, 1, 39, 39)\n",
    "    print(decoder_padding_mask.shape) # (64, 1, 1, 39) --> (64, 1, 39, 39)\n",
    "    print(decoder_mask.shape)         # (64, 1, 39, 39)\n",
    "    \n",
    "    return encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask\n",
    "\n",
    "temp_inp, temp_tar = iter(train_dataset.take(1)).next()\n",
    "print(temp_inp.shape, temp_tar.shape)\n",
    "creat_masks(temp_inp, temp_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 遍历数据集时的累记指标 并不是最终的指标参数\n",
    "train_loss = keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask \\\n",
    "    = creat_masks(inp, tar_inp)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, True, encoder_padding_mask,\n",
    "                                     decoder_mask, encoder_decoder_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)\n",
    "    \n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        if batch & 100 == 0:\n",
    "            print(\"Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}\".format(\n",
    "                epoch + 1,batch, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "        epoch + 1, train_loss.result(), train_accuray.result()))\n",
    "    print('Time for 1 epoch: {} seconds\\n'.format(time.time() - start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "'''\n",
    "A, B, C, D -> E\n",
    "A, B, C, D, E -> F\n",
    "A, B, C, D, E, F -> G\n",
    "'''\n",
    "\n",
    "def evaluate(inp_sentence):\n",
    "    input_id_sentence = [pt_tokenizer.vocab_size] \\\n",
    "    + pt_tokenizer.encode(inp_sentence) + [pt_tokenizer.vocab_size + 1]\n",
    "    \n",
    "    # shape = (1, input_sentence_len)\n",
    "    encoder_input = tf.expand_dims(input_id_sentence, 0)\n",
    "    \n",
    "    # shape = (1, 1)\n",
    "    decoder_input = tf.expand_dims([en_tokenizer.vocab_size], 0)\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        endoer_padding_mask, decoder_mask, encoder_decoder_padding_mask \\\n",
    "        = creat_masks(encoder_input, decoder_input)\n",
    "        \n",
    "        # pred.shape = (batch_size, output_target_len, target_vocab_size)\n",
    "        # output_target_len 就是decoder_input当前的长度\n",
    "        # 对于decoder_input中每一个值都会给出一个预测\n",
    "        # 但我们只需要最有一次的预测值， 即decoder_input全部输入进去后的预测值\n",
    "        predictions, attention_weights = transformer(encoder_input, decoder_input, \n",
    "                                                     False, encoder_padding_mask,\n",
    "                                                     decoder_mask,\n",
    "                                                     encoder_decoder_padding_mask)\n",
    "        # 切分，取出最后一个预测值\n",
    "        # shape = (batch_size, target_vocab_size)\n",
    "        predictions = predictions[:, -1, :]\n",
    "        \n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis = -1), tf.int32)\n",
    "        \n",
    "        if tf.equal(predicted_id, en_tokenizer.vocab_size + 1):\n",
    "            # decoder_input.shape = (1, target_len) 第一个维度没有用\n",
    "            return tf.squeeze(decoder_input, axis = 0), attention_weights\n",
    "        \n",
    "        # 如果直接[decoder_input, predicted_id] 维度错误\n",
    "        decoder_input = tf.concat([decoder_input, [predicted_id]], axis = -1)\n",
    "        \n",
    "    return tf.squeeze(decoder_input, axis = 0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encoder_decoder_attention(attention, input_sentence, result, layer_name):\n",
    "    # layer_name: key in attention_weights\n",
    "    fig = plt.figure(figsize = (16, 8))\n",
    "    \n",
    "    input_id_sentence = pt_tokenizer.encode(input_sentence)\n",
    "    # attetion[layer_name].shape = (batch_size, num_heads, tar_len, input_len)\n",
    "    # evaluate每次都只处理一个样本，batch_size = 1，消掉第一个维度\n",
    "    attention = tf.squeeze(attention[layer_name], axis = 0)\n",
    "    \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head + 1)\n",
    "        \n",
    "        # predicted_id 没有加上end_id，二者相等的时候就直接返回了\n",
    "        # 只有0到倒数第二个值会被放在attention矩阵中\n",
    "        ax.matshow(attention[head][:-1, :])\n",
    "        \n",
    "        fontdict = {'fontsize': 10}\n",
    "        \n",
    "        # 将input_sentence和result中对应的单词画到图中去，所以需要让图知道需要多少个锚点\n",
    "        # 每个锚点绘制一个单词  \n",
    "        # + 2有一个start_id, end_id\n",
    "        # range: 将长度转换成列表\n",
    "        ax.set_xticks(range(len(input_id_sentence) + 2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "        \n",
    "        ax.set_ylim(len(result) - 1.5, -0.5)\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>'] + [pt_tokenizer.decode([i]) for i in input_id_sentence] \\\n",
    "            + ['<end>'],fontdict = fontdict, rotation = 90)\n",
    "        ax.set_yticklabels(\n",
    "            [en_tokenizer.decode([i]) for i in result if i < en_tokenizer.vocab_size],\n",
    "            fontdict = fontdict)\n",
    "        ax.set_xlabel('Head {}'.format(head + 1))\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_sentence, layer_name = ''):\n",
    "    result_id, attention_weights = evaluate(input_sentence)\n",
    "    \n",
    "    # if的作用：1、不想decode start_id和end_id  2、超出id范围，decode会出错\n",
    "    predicted_sentence = en_tokenizer.decode(\n",
    "        [i for i in result_id if i < en_tokenizer.vocab_size])\n",
    "    \n",
    "    print(\"Input: {}\".format(input_sentence))\n",
    "    print(\"Predicted translation: {}\".format(predicted_sentence))\n",
    "    \n",
    "    if layer_name:\n",
    "        plot_encoder_decoder_attention(attention_weights, input_sentence, \n",
    "                                       result_id, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"\", layer_name = 'decoder_layer4_attn2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
